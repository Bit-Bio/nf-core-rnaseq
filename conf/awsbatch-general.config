// Config for aws batch on bitbio 

// This is the working directory for the pipeline.
// To change the pipeline_name, the variable is in the nextflow.config file or use the --pipeline_name flag.
//workDir = "s3://bitbio-pipelines/${params.pipeline_name}/temp/${params.user_name}/"

params {

  config_profile_name = 'AWS Batch profile'
  config_profile_description = 'This is the core profile for running Nextflow jobs on AWS Batch'
  config_profile_contact = ''

  awsqueue = 'highpriority-eb16b4c0-d8dc-11ea-922f-0a0207fddeaf'
  awsregion = 'us-east-1'
}

aws {
    region = params.awsregion
}

docker {
	enabled = true
	// Avoid this error:
	// WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
	// Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351
	// once this is established and works well, nextflow might implement this behavior as new default.
	runOptions = '-u \$(id -u):\$(id -g)'
	// For info on the z flag look here: https://github.com/nf-core/nanoseq/issues/74
	fixOwnership = true
}

process {

  queue = params.awsqueue
  executor = 'awsbatch'

  cpus   = { check_max( 1    * task.attempt, 'cpus'   ) }
  memory = { check_max( 6.GB * task.attempt, 'memory' ) }
  time   = { check_max( 4.h  * task.attempt, 'time'   ) }

  errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'finish' }
  maxRetries    = 1
  maxErrors     = '-1'

  // Process-specific resource requirements
    withLabel:process_verylow {
      cpus   = { check_max( 1     * task.attempt, 'cpus'    ) }
      memory = { check_max( 4.GB * task.attempt, 'memory'  ) }
      time   = { check_max( 4.h   * task.attempt, 'time'    ) }
  }

  withLabel:process_low {
      cpus   = { check_max( 2     * task.attempt, 'cpus'    ) }
      memory = { check_max( 8.GB * task.attempt, 'memory'  ) }
      time   = { check_max( 4.h   * task.attempt, 'time'    ) }
  }
  withLabel:process_medium {
      cpus   = { check_max( 6     * task.attempt, 'cpus'    ) }
      memory = { check_max( 36.GB * task.attempt, 'memory'  ) }
      time   = { check_max( 8.h   * task.attempt, 'time'    ) }
  }
  withLabel:process_high {
      cpus   = { check_max( 12    * task.attempt, 'cpus'    ) }
      memory = { check_max( 72.GB * task.attempt, 'memory'  ) }
      time   = { check_max( 16.h  * task.attempt, 'time'    ) }
  }
  withLabel:process_long {
      time   = { check_max( 24.h  * task.attempt, 'time'    ) }
  }
  withLabel:process_high_memory {
      memory = { check_max( 200.GB * task.attempt, 'memory' ) }
  }
}
